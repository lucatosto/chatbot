{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "# Copyright 2015 Conchylicultor. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Main script. See README.md for more informations\n",
    "\n",
    "Use python 3\n",
    "\"\"\"\n",
    "\n",
    "import argparse # Command line parsing\n",
    "import time # Chronometter the timing\n",
    "import os # For saving the model\n",
    "#import tensorflow as tf\n",
    "\n",
    "from textdata import TextData\n",
    "#from model import Model\n",
    "\n",
    "# For testing only\n",
    "from cornelldata import CornellData\n",
    "\n",
    "\n",
    "def parseArgs():\n",
    "    \"\"\"\n",
    "    Parse the agruments from the given command line\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--corpus', type=str, default='cornell', help='dataset to choose (cornell)')\n",
    "    parser.add_argument('--save', type=str, default='save', help='directory to load checkpointed models')\n",
    "    parser.add_argument('--load', type=str, default='save', help='directory to store checkpointed models')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Launch the training and/or the interactive mode\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"ICS Chatbot v0.1 !\")\n",
    "    print()\n",
    "\n",
    "\n",
    "    args = parseArgs();\n",
    "\n",
    "\n",
    "    textData = TextData(args)\n",
    "    #model = Model(args)\n",
    "\n",
    "    #with tf.Session() as sess:\n",
    "    #    tf.initialize_all_variables().run()\n",
    "\n",
    "    #    pass\n",
    "\n",
    "    #with tf.Session() as sess:\n",
    "        #tf.initialize_all_variables().run()\n",
    "        #saver = tf.train.Saver(tf.all_variables())\n",
    "        #for e in range(args.num_epochs):\n",
    "            #sess.run(tf.assign(model.lr, args.learning_rate * (args.decay_rate ** e)))\n",
    "            #data_loader.reset_batch_pointer()\n",
    "            #state = model.initial_state.eval()\n",
    "            #for b in range(data_loader.num_batches):\n",
    "                #start = time.time()\n",
    "                #x, y = data_loader.next_batch()\n",
    "                #feed = {model.input_data: x, model.targets: y, model.initial_state: state}\n",
    "                #train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\n",
    "                #end = time.time()\n",
    "                #print(\"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\" \\\n",
    "                    #.format(e * data_loader.num_batches + b,\n",
    "                            #args.num_epochs * data_loader.num_batches,\n",
    "                            #e, train_loss, end - start))\n",
    "\n",
    "                ## Save the model\n",
    "                #if (e * data_loader.num_batches + b) % args.save_every == 0\\\n",
    "                    #or (e==args.num_epochs-1 and b == data_loader.num_batches-1): # save for the last result\n",
    "                    #checkpoint_path = os.path.join(args.save_dir, 'model.ckpt')\n",
    "                    #saver.save(sess, checkpoint_path, global_step = e * data_loader.num_batches + b)\n",
    "                    #print(\"model saved to {}\".format(checkpoint_path))\n",
    "\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
